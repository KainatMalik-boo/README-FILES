# README-FILES
2k18/CSM/50 "KAINAT MALIK"
PAPER 1
DBUGGING HIRING: WHAT WENT RIGHT 	AND WHAT WENT WRONG IN THE 	TECHNICAL INTERVIEW PROCESS
The author of this title is “Mahnaz Bheroozi”, “Shivani Shirolkar”, “Titus Barik”, “Chris Parnin”. It`s conference name is “International Conference on Software Engineering” (ICSE-SEIS’20), it was published on “May 23-29, 2020”at “Seoul, republic of Korea”. 

INTRODUCTON:
This discussion about hire the new employees for join the companies. This pipeline for software engineering candidates, who gives the interview. This pipeline arranges the Interview days, interview conducted over the mobile(video) and through online system platforms. If candidates select in this interview process so we are invited to candidates for one more technical interview that involves whiteboard or simple text editor.
In this hiring pipeline, the chronological process yields a positive result for all interviewers who take the decision for hire those candidates who deserved this job.
The candidate is happy that they have found a job according to their skills, interest and values, the company is confident about the employee and those candidates rejected in the technical interview, they have better understanding that they were not a good fit for the job. They need to improve, this is motivation of the debugging hiring



  IMPORTANCE OF DBUGGING HIRING:
The importance of debugging hiring is conducting the interviews, select the best candidates for the companies.
•	A candidate`s first conversation with your company, typically discussion about new ideas for the company and tells about which companies are good for new deals, is the important step for hiring process.
•	Interview process say a lot about your organization, if your company unorganized so you are losing top candidates.
•	First impression matter about both company and candidates.
•	Candidate have positive experience.
•	To ask question about related to job.
If only two candidates apply two openings, you may have choice to hire them. But if 20 candidates apply so you can use techniques (online system)

METHODOLOGY:
In the content of software engineering debugging is the process to understand that how to become disengaged during the hiring process, it refers to identify and analysis the qualitative on interview reviews, then we collect the data about technical interviews for software engineering position. Glass door.com is a website for find the job that`s fit your life. In this field so many companies a appear in this website there are at least 50 reviews on Glass door. This yielded a total of 19 companies to collect the data. Reviews spanned from March 5, 2009 to June 25, 2019.
Organize our collected data in to reviews such as ‘Positive Experience’ and Negative Experience’ we analysis the reviews if they did not a positive and negative experience. We removed the non-informative reviews.

RESULT:
We discuss the result about both negative (what went wrong) and positive (what went right) there are some themes found studying the hiring pipeline.
and give example about what went wrong and what went right.

Contact:
In this theme we ask about candidate’s experiences on the initial phases in the hiring pipeline and candidate response to the recruiter. Paying attention to details where recruiter make mistake in matching the candidate to a position. Responsive can keep candidates a potentially long and uncertain hiring process, candidate except recruiter to response in a timely manner throughout the hiring process. Example: (What went wrong?) “I tried calling back the recruiter but they just do not respond. . .had to withdraw my application.” 
(What went right?) “I got prompt response from this point till the end. . . everyone was professional.” 

Preparation:
After initial phases companies prepare the candidates for what to expect. Interview scheduling important in the hiring process. Candidate were not available to proceed with the interviews. hiring criteria when companies went accurate result but companies are not clear on their hiring criteria.
Example: (What went wrong?) “My interview was rescheduled three times, which
as a candidate provides a terrible experience, especially as I am currently
employed full-time.”
(What went right?) “Very flexible. . . I asked the recruiter to schedule
interviews during time that would not impact my activities. I was surprised when he proposed the first one on a Saturday morning.”
Interviews: 
Candidate interaction with the interviewers for positive and negative outcome.
Interviews can act as shepherd through a stressful interview.
Example: (What went wrong?) “The next interviewer was a very jaded engineer
who clearly didn’t want to be there. Unresponsive to questions. It was very
awkward and put me off in a major way.” 
(What went right?) “Interviewer was smart and polite; asking ‘logical’
questions rather than trying to show off or stump-the-candidate sort of
questions.” 
Hearing Back:
when someone not responding to messages then company was not interested in them. Example: (What went wrong?) “I can deal with rejection. I cannot deal with poor processes, especially when followed by a generic rejection letter, and no opportunity for feedback.” 
(What went right?) “Overall, the interview experience was pretty good and I got feedback in a decent amount of time.”
Offer and Negotiation:
This is the final stage of hiring process, it is a waste of time for company and candidates. Example: (What went wrong?) “The team matching progress is extremely slow and the recruiter is reluctant to arrange it. Took around three months to finish everything, way too long. Declined the offer without hesitation.”
(What went right?) “They were aware that I had a pending offer that I had to make a decision on, and were very good about moving the process along as quickly as possible.” 

CONCLUSION:
The hiring pipeline for software engineering has become ubiquitous with in industry as mean to recruit and selected candidates. Candidate to understand their experiences with in the hiring pipeline. To find how leaky hiring pipelines materialize across all of the stages of the pipeline. Our findings inform guidelines that if stand to make the hiring pipeline more inclusive.


PAPER 2
EXPERIMENTATION FOR BUSINESS-TO-BUSINESS MISSION CRITICAL SYSTEMS:    					A CASE STUDY
The author of this title is “David Issa Mattos”, “Anas Dakkak”, “Jan Bosch”, “Helena Holmstrom Olsson”. It`s conference name is “International Conference on Software Engineering” (ICSSP’20), it was published on “October 10-11, 2020”at “Seoul, republic of Korea”. 

INTRODUCTON:
Business-to-Business is a situation where one business make a commercial transaction with another for example one business connected to many business, it`s type of marketing strategy another example, in the telecommunication domain, mobile networks are continuously evolving to support new user equipment (such as consumer electronics, medical equipment, payment and navigation systems) and to improve the quality of the delivered service to their customer and final users.
Large-scale web-facing companies (such as Google, Amazon, Microsoft, Netflix among others) continuously reporting success stories and the competitive advantage the continuous experimentation (CE). Introduction of (CE) in a business to business (B2B) context [14, 21, 22], no publications explore or discuss the industrial usage of experimentation on business to business mission critical systems.
A mission critical system is a system that is essential to the survival of a business or organization. The work refers to mission-critical system as in the presence of the failure or degradation in the system can lead to lead to property damage, as well as the main task to be fully success (to achieve a particular goal) HURRIER(High valued software through continuous experimentation) we describe the process as a set of generic  activities organize in main areas implemented the organization as well as the customer.
METHODOLOGY:
The purpose of this methodology is to understanding of the continuous experimentation process, when it is applied in mission-critical functionalities in business to business domain. We allow the researcher to study about the case study and understand the phenomenon of the mission-critical and B2B system. There are five steps for a case study as are follow.
1.	Case study design: the objectives are defined and the study is planned
2.	Preparation for data collection: procedures and protocols for data collection are define 
3.	Collecting evidence: execution with the data collection on the study case 
4.	Analysis of the collected data
5.	Reporting of the result

CASE COMPANY:
This research was conducted at Ericsson AB, which is a multinational networking and telecommunications company that develops, produces and sells telecommunication equipment, services, software and infrastructure to telecommunication operators in both mobile and fixed broadband. Experiments in Ericsson are used in a large number of use cases ranging from innovation and new feature development to legacy assurance and performance optimization.

DATA COLLECTION: The data collected in this case study consists of a mix of different data sources, including transcripts of semi-structured interviews, notes from meetings, emails, documentation and presentations. He was involved in several of the project meetings and was also responsible for the selection of the interviews for this study. We utilized a combination of criterion sampling with convenience sampling, where we interviewed the practitioners who were knowledgeable and accepted to participate in this study.

DATA ANALYSIS:
All data collected described previously were added to the qualitative analysis software NVivo, where a thematic coding analysis was utilized, according to the six-phase process.

1.	The phase consists of familiarizing with the data. 
2.	The phase, we generated the first set of codes, representing interesting concepts and ideas captured in the interviews or discussed in the additional documents. 
3.	The phase, we discussed potential themes for the identified codes. 
4.	The phase, we reviewed the potential themes and merged similar codes when possible and classified them as part of the theme-groups: experimentation activities, B2B challenges, mission-critical challenges, perceived advantages, customer involvement, etc. 
5.	The phase, we analyzed each theme individually, generating the main results and discussion points to answer each research question.
6.	 The last phase consists of this publication, where the results are presented and the research questions explicitly answered in the discussion.

HURRIER PROCESS:
The HURRIER process was identified and formulated based on the current experimentation practices of different teams inside Ericsson. is used in its entirety or just a subset of its activities depending on the scope and area of the development project. The process is composed of a set of generic activities that can be organized in four main areas around two feedback channels. The areas are: 

1.	The R&D organization, is responsible for the development of the feature or change that is going to be deployed.
2.	The internal validation, consists of quality assurance activities. 
3.	Single customer validation, provides software with enough quality and verification to be deployed in the field.
4.	Multiple customer validation, If the field experiments with the first customer already provide enough coverage and confidence in the solution, in terms of quality or value, the R&D organization can decide to mark the feature for general availability (GA) which means that the feature has the adequate quality and therefore ready to be deployed by any customer.

CONCLUSION: 
In collaboration with Ericsson, we conducted a case study to understand how to CE can be used in the B2B domain, and investigate how this process can be used with mission-critical features. This process describes the deployment of experiments within the B2B domain and also takes into account considerations for running experiments with mission-critical features.


PAPER3

TRANSLATING VIDEO RECORDING OF MOBILE APP USAGE IN TO REPLAYABLE 						SCENARIOS
The author of this title is “Carlos Bernal-Cardenas”, “Nathan Cooper”, “Kevin Moran”, “Oscar Chaparro”, “Andrian Marcus”, “Denys Poshyvanyk”. It`s conference name is “International Conference on Software Engineering” (ICSE’20), it was published on “May 23-29, 2020”at “Seoul, republic of Korea”. 

INTRODUCTION:
These information sources include user reviews, crash reports, bug reports, and emails, among others. An increasingly common component of these software artifacts is graphical information, such as screenshots or screen recordings. In fact, many crowd-testing and bug reporting frameworks have built-in screen recording features to help developers collect mobile application usage data and faults [6, 7, 21, 22]. 
1.	Help understand how users interact with apps [14, 68]. 
2.	Process bug reports and feature requests from end-users [27].
3.	Aid in bug comprehension for testing related tasks [53].
The manual effort required by this comprehension process complicates a development workflow that is already constrained by language dichotomies [55] and several challenges unique to mobile software, including: 
1.	Pressure for frequent releases [39, 43].
2.	Rapidly evolving platforms and APIs [24, 49].
3.	Constant noisy feedback from users [30, 31, 62–64]. 
4.	Fragmentation in the mobile device ecosystem [1, 37, 72] among others [51]. 
To improve and automate the analysis of video-related mobile development artifacts, we introduce Video to Scenario (V2S), a lightweight automated approach for translating video screen recordings of Android app usages into replayable scenarios. V2S adapts recent Deep Learning (DL) models for object detection and image classification to accurately detect and classify different types of user actions performed on the screen. We conducted a comprehensive evaluation of V2S using both videos collected from users reproducing bugs as well as general usage videos from the top-rated apps of 32 categories in the Google Play market.
The results of our evaluation indicate that V2S is accurate, and is able to correctly reproduce 89% of events across collected videos. In summary, the main contributions of our work are as follows: 
1.	V2S, the first record-and-replay approach for Android that functions purely on screen-recordings of app usages.
2.	An automated pipeline for dataset generation and model training to identify user interactions from screen recordings.
3.	The results of an extensive empirical evaluation of V2S that measures the accuracy, robustness, and efficiency across 175 videos from 80 applications.
4.	The results of a case study with three industrial partners, who develop commercial apps, highlighting V2S’s potential usefulness, as well as areas for improvement and extension.
5.	An online appendix [26], which contains examples of videos replayed by V2S, experimental data, source code, trained models, and our evaluation.

THE V2S APPROACH:
V2S’s architecture, which is divided into three main phases:

Touch Detection phase, which identifies user touches in each frame of an input video. 
Action Classification phase that groups and classifies the detected touches into discrete user actions (i.e., tap, long-tap, and swipe). 
Scenario Generation phase that exports and formats these actions into a replayable script.
METHODOLOGY:
we describe the procedure we used to evaluate V2S.
The main quality focus of our study is the extent to which V2S can generate replayable scenarios that mimic original user GUI inputs. To achieve our study goals, we formulated the following five research questions: 
• RQ1: How accurate is V2S in identifying the location of the touch indicator? 
• RQ2: How accurate is V2S in identifying the opacity of the touch indicator? 
• RQ3: How effective is V2S in generating a sequence of events that accurately mimics the user behavior from video recordings of different applications? 
• RQ4: What is V2S’s overhead in terms of scenario generation?
• RQ5: Do practitioners perceive V2S as useful?

Accuracy of Faster R-CNN:
We first evaluated the ability of V2S’s Faster RCNN to accurately identify and localize the touch indicators present in screen recording frames with bounding boxes.

Accuracy of Opacity CNN:
We evaluated the ability of V2S’s Opacity CNN to predict whether the opacity of the touch indicator is solid or semitransparent.

Accuracy on Different Scenarios:
we carried out two studies designed to assess both the depth, and breadth of V2S’s abilities to reproduce user events depicted in screen recordings. The first, Controlled Study, measures the depth of V2S’s abilities through a user study during which we collected real videos from end users depicting: bugs, real crashes, synthetically injected crashes, and normal usage scenarios for 20 apps. Next in the Popular Applications Study we measured the breadth of V2S’s abilities by recording scenarios for a larger, more diverse set of 64 most popular apps from the Google Play.
Performance:
To investigate RQ4, we evaluated V2S by calculating the average time it takes for a video to pass through each of the three phases of the V2S approach on commodity hardware (i.e., a single NVIDIA GTX 1080Ti). We see this as a worst-case scenario for V2S performance, as our approach could perform substantially faster on specialized hardware.

Perceived Usefulness:
Ultimately, our goal is to integrate V2S into real-world development environments. Thus, as part of our evaluation, we investigated V2S’s perceived usefulness with three developers who build Android apps (or web apps for mobile) for their respective companies.

CONCLUSION:
We have presented V2S, an approach for automatically translating video recordings of Android app usages into replayable scenarios. A comprehensive evaluation indicates that V2S: Accurately identifies touch indicators and it is able to differentiate between opacity levels, is capable of reproducing a high percentage of complete scenarios related to crashes and other bugs, with promising results for general user scenarios as well, and is potentially useful to support real developers during a variety of tasks. 
